{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ff7856-0fa4-496e-858d-e54efdc4dc20",
   "metadata": {},
   "source": [
    "# Import Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f7e921-7481-495c-b511-465133393920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jupyterlab_widgets\n",
    "\n",
    "# PyTorch\n",
    "#!pip install torch torchvision torchaudio\n",
    "\n",
    "# Optional: Hugging Face Transformers\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d19bfb-0820-45a2-a24a-8d8e00ab13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR TensorFlow\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a470427-c796-4831-98a2-cf135190e855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status\n",
       "0           0                                         oh my gosh  Anxiety\n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df = pd.read_csv(\"Combined Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213b50be-6ee9-4815-b07a-352d75e061cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      0\n",
      "statement     362\n",
      "status          0\n",
      "dtype: int64\n",
      "Unnamed: 0    0.00\n",
      "statement     0.68\n",
      "status        0.00\n",
      "dtype: float64\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "# 1. Quick summary: count of missing values per column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Percentage of missing values per column\n",
    "print((df.isnull().mean() * 100).round(2))\n",
    "\n",
    "# 3. Total number of missing values in the entire DataFrame\n",
    "print(df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881e517a-7c02-403c-a0db-625895a98708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['statement'])\n",
    "print(df['statement'].isnull().sum())  # Should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d696c0-f39d-4a5f-8c90-c151eb6774a9",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b384538-d040-4d27-a955-20f4ed851384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text column\n",
    "df['statement'] = df['statement'].astype(str)  # Force all values to string\n",
    "df = df[df['statement'].notnull()]        # Remove rows where text is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82632722-62cd-4498-822e-7645fd95aadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Yap Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Yap Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources (do it once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Processing Steps\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70d45f0-fb2a-495f-b10f-6e0ea77d4fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final preprocessed text:\n",
      " i not sure you go like i feel quite lately nothing seem work i not say i happy however i not want give not strange life change quickly we try best we not not let anyone tell you otherwise\n"
     ]
    }
   ],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create stopwords set but keep negative and pronouns\n",
    "stop_words = set(stopwords.words('english'))\n",
    "negation_words = {\"no\", \"nor\", \"not\", \"don\", \"don't\", \"ain\", \"aren\", \"aren't\",\n",
    "                  \"couldn\", \"couldn't\", \"didn\", \"didn't\", \"doesn\", \"doesn't\",\n",
    "                  \"hadn\", \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\",\n",
    "                  \"isn\", \"isn't\", \"mightn\", \"mightn't\", \"mustn\", \"mustn't\",\n",
    "                  \"needn\", \"needn't\", \"shan\", \"shan't\", \"shouldn\", \"shouldn't\",\n",
    "                  \"wasn\", \"wasn't\", \"weren\", \"weren't\", \"won\", \"won't\",\n",
    "                  \"wouldn\", \"wouldn't\"}\n",
    "\n",
    "pronouns_to_keep = {'i', 'you', 'he', 'she', 'we', 'they', 'me', 'him', 'her', 'us', 'them'}\n",
    "\n",
    "stop_words = stop_words - negation_words - pronouns_to_keep\n",
    "\n",
    "# Expand contractions function\n",
    "def expand_contractions(text):\n",
    "    contractions = {\n",
    "        \"i'm\": \"i am\", \"i've\": \"i have\", \"i'll\": \"i will\", \"don't\": \"do not\",\n",
    "        \"can't\": \"cannot\", \"won't\": \"will not\", \n",
    "        \"it isn't\": \"it is not\", \"isn't it\": \"is it not\",\n",
    "        \"wasn't it\": \"was it not\", \"it wasn't\": \"it was not\",\n",
    "        \"they aren't\": \"they are not\", \"aren't they\": \"are they not\",\n",
    "        \"aren't we\": \"are we not\", \"we aren't\": \"we are not\", \"aren't i\": \"am i not\",\n",
    "        \"weren't they\": \"were they not\", \"they weren't\": \"they were not\",\n",
    "        \"you're\": \"you are\", \"he's\": \"he is\", \"she's\": \"she is\", \"it's\": \"it is\",\n",
    "        \"we're\": \"we are\", \"they're\": \"they are\"\n",
    "    }\n",
    "\n",
    "    # Create regex pattern with word boundaries, ignore case\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, contractions.keys())) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "    def match_case(original, replacement):\n",
    "        if original.isupper():\n",
    "            return replacement.upper()\n",
    "        elif original[0].isupper():\n",
    "            return replacement.capitalize()\n",
    "        else:\n",
    "            return replacement\n",
    "\n",
    "    def replace(match):\n",
    "        original = match.group(0)\n",
    "        contraction = original.lower()\n",
    "        expanded = contractions.get(contraction, contraction)\n",
    "        return match_case(original, expanded)\n",
    "\n",
    "    return pattern.sub(replace, text)\n",
    "\n",
    "\n",
    "# Helper to convert nltk POS tags to WordNet POS tags for lemmatizer\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = expand_contractions(text)\n",
    "\n",
    "    # Sentence tokenize\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Remove non-alphanumeric characters (excluding apostrophes)\n",
    "    cleaned_sentences = [re.sub(r\"[^a-zA-Z0-9\\s']\", \" \", s) for s in sentences]\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = []\n",
    "    for s in cleaned_sentences:\n",
    "        tokens.extend(word_tokenize(s))\n",
    "\n",
    "    # POS tagging on original tokens (before case folding)\n",
    "    # I acknowledge that spaCy provides more accurate POS tagging compared to NLTK's pos_tag.\n",
    "    # However, due to resource constraints and familiarity with NTLK, pos_tag is used here.\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Case folding AFTER POS tagging\n",
    "    pos_tags = [(word.lower(), tag) for word, tag in pos_tags]\n",
    "\n",
    "    # Lemmatization using POS\n",
    "    lemmatized = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(pos))\n",
    "        for word, pos in pos_tags\n",
    "    ]\n",
    "\n",
    "    # Stopword filtering\n",
    "    filtered = [word for word in lemmatized if word not in stop_words]\n",
    "\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Sample test\n",
    "sample_text = \"I'm not sure if you're going to like this! I've been feeling quite down lately — nothing seems to work, and I can't say I'm happy. However, I don't want to give up. Isn't it strange how life changes so quickly? We're trying our best, aren't we? Don't let anyone tell you otherwise.\"\n",
    "\n",
    "cleaned_text = preprocess_text(sample_text)\n",
    "print(\"\\nFinal preprocessed text:\\n\", cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27bcc535-7043-4d47-9c1f-4f6055cbbeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef preprocess_text(text):\\n    print(\"Original Text:\\n\", text, \"\\n\")\\n\\n    # 1. Expand contractions\\n    text = expand_contractions(text)\\n    print(\"After Contraction Expansion:\\n\", text, \"\\n\")\\n\\n    # 2. Sentence tokenization\\n    sentences = sent_tokenize(text)\\n    print(\"Sentences:\\n\", sentences, \"\\n\")\\n\\n    # 3. Remove non-alphanumeric characters (except apostrophes)\\n    cleaned_sentences = [re.sub(r\"[^a-zA-Z0-9\\\\s\\']\", \" \", s) for s in sentences]\\n    print(\"After Removing Punctuation:\\n\", cleaned_sentences, \"\\n\")\\n\\n    # 4. Word tokenization\\n    tokens = []\\n    for s in cleaned_sentences:\\n        tokens.extend(word_tokenize(s))\\n    print(\"Tokens:\\n\", tokens, \"\\n\")\\n\\n    # 5. POS tagging\\n    pos_tags = nltk.pos_tag(tokens)\\n    print(\"POS Tags:\\n\", pos_tags, \"\\n\")\\n\\n    # 6. Case folding after POS tagging\\n    pos_tags = [(word.lower(), tag) for word, tag in pos_tags]\\n    print(\"POS Tags After Case Folding:\\n\", pos_tags, \"\\n\")\\n\\n    # 7. Lemmatization using POS\\n    lemmatized = [\\n        lemmatizer.lemmatize(word, get_wordnet_pos(pos))\\n        for word, pos in pos_tags\\n    ]\\n    print(\"Lemmatized:\\n\", lemmatized, \"\\n\")\\n\\n    # 8. Remove stopwords (excluding negation and pronouns)\\n    filtered = [word for word in lemmatized if word not in stop_words]\\n    print(\"Filtered (No Stopwords):\\n\", filtered, \"\\n\")\\n\\n    # Final output\\n    final_output = \\' \\'.join(filtered)\\n    print(\"Final Output:\\n\", final_output, \"\\n\")\\n    return final_output\\n\\n# Sample test\\nsample_text = \"I\\'m not sure if you\\'re going to like this! I\\'ve been feeling quite down lately — nothing seems to work, and I can\\'t say I\\'m happy. However, I don\\'t want to give up. Isn\\'t it strange how life changes so quickly? We\\'re trying our best, aren\\'t we? Don\\'t let anyone tell you otherwise.\"\\n\\ncleaned_text = preprocess_text(sample_text)\\nprint(\"\\nFinal preprocessed text:\\n\", cleaned_text)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is only for testing and debugging purposes \n",
    "\n",
    "\"\"\"\n",
    "def preprocess_text(text):\n",
    "    print(\"Original Text:\\n\", text, \"\\n\")\n",
    "\n",
    "    # 1. Expand contractions\n",
    "    text = expand_contractions(text)\n",
    "    print(\"After Contraction Expansion:\\n\", text, \"\\n\")\n",
    "\n",
    "    # 2. Sentence tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    print(\"Sentences:\\n\", sentences, \"\\n\")\n",
    "\n",
    "    # 3. Remove non-alphanumeric characters (except apostrophes)\n",
    "    cleaned_sentences = [re.sub(r\"[^a-zA-Z0-9\\s']\", \" \", s) for s in sentences]\n",
    "    print(\"After Removing Punctuation:\\n\", cleaned_sentences, \"\\n\")\n",
    "\n",
    "    # 4. Word tokenization\n",
    "    tokens = []\n",
    "    for s in cleaned_sentences:\n",
    "        tokens.extend(word_tokenize(s))\n",
    "    print(\"Tokens:\\n\", tokens, \"\\n\")\n",
    "\n",
    "    # 5. POS tagging\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    print(\"POS Tags:\\n\", pos_tags, \"\\n\")\n",
    "\n",
    "    # 6. Case folding after POS tagging\n",
    "    pos_tags = [(word.lower(), tag) for word, tag in pos_tags]\n",
    "    print(\"POS Tags After Case Folding:\\n\", pos_tags, \"\\n\")\n",
    "\n",
    "    # 7. Lemmatization using POS\n",
    "    lemmatized = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(pos))\n",
    "        for word, pos in pos_tags\n",
    "    ]\n",
    "    print(\"Lemmatized:\\n\", lemmatized, \"\\n\")\n",
    "\n",
    "    # 8. Remove stopwords (excluding negation and pronouns)\n",
    "    filtered = [word for word in lemmatized if word not in stop_words]\n",
    "    print(\"Filtered (No Stopwords):\\n\", filtered, \"\\n\")\n",
    "\n",
    "    # Final output\n",
    "    final_output = ' '.join(filtered)\n",
    "    print(\"Final Output:\\n\", final_output, \"\\n\")\n",
    "    return final_output\n",
    "\n",
    "# Sample test\n",
    "sample_text = \"I'm not sure if you're going to like this! I've been feeling quite down lately — nothing seems to work, and I can't say I'm happy. However, I don't want to give up. Isn't it strange how life changes so quickly? We're trying our best, aren't we? Don't let anyone tell you otherwise.\"\n",
    "\n",
    "cleaned_text = preprocess_text(sample_text)\n",
    "print(\"\\nFinal preprocessed text:\\n\", cleaned_text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3fa9cbf-bcdf-46a7-8eb4-a606a2872800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>oh gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>trouble sleep confuse mind restless heart tune</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>i shift focus something else i still worried</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>i restless restless month boy you mean</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53038</th>\n",
       "      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n",
       "      <td>nobody take me seriously i 24m dealt depressio...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53039</th>\n",
       "      <td>selfishness  \"I don't feel very good, it's lik...</td>\n",
       "      <td>selfishness i not feel good like i not belong ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53040</th>\n",
       "      <td>Is there any way to sleep better? I can't slee...</td>\n",
       "      <td>way sleep good i not sleep night med n't help</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53041</th>\n",
       "      <td>Public speaking tips? Hi, all. I have to give ...</td>\n",
       "      <td>public speak tip hi i give presentation work n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53042</th>\n",
       "      <td>I have really bad door anxiety! It's not about...</td>\n",
       "      <td>i really bad door anxiety not scar i n't lock ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement  \\\n",
       "0                                             oh my gosh   \n",
       "1      trouble sleeping, confused mind, restless hear...   \n",
       "2      All wrong, back off dear, forward doubt. Stay ...   \n",
       "3      I've shifted my focus to something else but I'...   \n",
       "4      I'm restless and restless, it's been a month n...   \n",
       "...                                                  ...   \n",
       "53038  Nobody takes me seriously I’ve (24M) dealt wit...   \n",
       "53039  selfishness  \"I don't feel very good, it's lik...   \n",
       "53040  Is there any way to sleep better? I can't slee...   \n",
       "53041  Public speaking tips? Hi, all. I have to give ...   \n",
       "53042  I have really bad door anxiety! It's not about...   \n",
       "\n",
       "                                            cleaned_text   status  \n",
       "0                                                oh gosh  Anxiety  \n",
       "1         trouble sleep confuse mind restless heart tune  Anxiety  \n",
       "2      wrong back dear forward doubt stay restless re...  Anxiety  \n",
       "3           i shift focus something else i still worried  Anxiety  \n",
       "4                 i restless restless month boy you mean  Anxiety  \n",
       "...                                                  ...      ...  \n",
       "53038  nobody take me seriously i 24m dealt depressio...  Anxiety  \n",
       "53039  selfishness i not feel good like i not belong ...  Anxiety  \n",
       "53040      way sleep good i not sleep night med n't help  Anxiety  \n",
       "53041  public speak tip hi i give presentation work n...  Anxiety  \n",
       "53042  i really bad door anxiety not scar i n't lock ...  Anxiety  \n",
       "\n",
       "[52681 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['statement'].apply(preprocess_text)\n",
    "df[['statement', 'cleaned_text', 'status']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7c144-0616-4a5e-a0f0-abb827c1813d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88b307-4783-4909-9801-496f478e7d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08721d57-5cfe-497d-8f4f-d18658e6ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Normal': 16343, 'Depression': 15404, 'Suicidal': 10652, 'Anxiety': 3841, 'Bipolar': 2777, 'Stress': 2587, 'Personality disorder': 1077})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(df[\"status\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43090be-07a0-46fa-9fc8-c654367ff8ac",
   "metadata": {},
   "source": [
    "# Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90368e4b-b62e-4e29-9574-7095e265d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob\n",
    "# !pip install vaderSentiment\n",
    "# !pip install afinn\n",
    "# !pip install pywsd nltk\n",
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cb1bb-4d67-41aa-8652-5c0e1bb7c2d4",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a09a89f1-d93c-451f-bb2f-e44c5db12e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_ner(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "df[\"named_entities\"] = df[\"statement\"].apply(extract_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a4c6e-c213-421e-bf8d-16699160fd51",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation (WSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0de2bb78-0091-40ab-be9e-ca47f7fc004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def disambiguate(text, word):\n",
    "    tokens = word_tokenize(text)\n",
    "    sense = lesk(tokens, word)\n",
    "    return sense.definition() if sense else None\n",
    "\n",
    "# Example: Apply WSD to the word \"stress\" (you can adjust this)\n",
    "df[\"wsd_stress\"] = df[\"statement\"].apply(lambda x: disambiguate(x, \"stress\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662ab79-b136-4b2a-af8f-00fa07dc6851",
   "metadata": {},
   "source": [
    "## Sentiment Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d63355f-1a08-4243-8884-d52abeca3f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Yap\n",
      "[nltk_data]     Jack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>oh gosh</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>trouble sleep confuse mind restless heart tune</td>\n",
       "      <td>-0.6908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "      <td>-0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>i shift focus something else i still worried</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>i restless restless month boy you mean</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53038</th>\n",
       "      <td>53038</td>\n",
       "      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>nobody take me seriously i 24m dealt depressio...</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53039</th>\n",
       "      <td>53039</td>\n",
       "      <td>selfishness  \"I don't feel very good, it's lik...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>selfishness i not feel good like i not belong ...</td>\n",
       "      <td>-0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53040</th>\n",
       "      <td>53040</td>\n",
       "      <td>Is there any way to sleep better? I can't slee...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>way sleep good i not sleep night med n't help</td>\n",
       "      <td>0.1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53041</th>\n",
       "      <td>53041</td>\n",
       "      <td>Public speaking tips? Hi, all. I have to give ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>public speak tip hi i give presentation work n...</td>\n",
       "      <td>-0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53042</th>\n",
       "      <td>53042</td>\n",
       "      <td>I have really bad door anxiety! It's not about...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>i really bad door anxiety not scar i n't lock ...</td>\n",
       "      <td>-0.9195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52681 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          statement   status  \\\n",
       "0               0                                         oh my gosh  Anxiety   \n",
       "1               1  trouble sleeping, confused mind, restless hear...  Anxiety   \n",
       "2               2  All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
       "3               3  I've shifted my focus to something else but I'...  Anxiety   \n",
       "4               4  I'm restless and restless, it's been a month n...  Anxiety   \n",
       "...           ...                                                ...      ...   \n",
       "53038       53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety   \n",
       "53039       53039  selfishness  \"I don't feel very good, it's lik...  Anxiety   \n",
       "53040       53040  Is there any way to sleep better? I can't slee...  Anxiety   \n",
       "53041       53041  Public speaking tips? Hi, all. I have to give ...  Anxiety   \n",
       "53042       53042  I have really bad door anxiety! It's not about...  Anxiety   \n",
       "\n",
       "                                            cleaned_text   score  \n",
       "0                                                oh gosh  0.0000  \n",
       "1         trouble sleep confuse mind restless heart tune -0.6908  \n",
       "2      wrong back dear forward doubt stay restless re... -0.7351  \n",
       "3           i shift focus something else i still worried -0.2960  \n",
       "4                 i restless restless month boy you mean -0.4939  \n",
       "...                                                  ...     ...  \n",
       "53038  nobody take me seriously i 24m dealt depressio...  0.8696  \n",
       "53039  selfishness i not feel good like i not belong ... -0.9830  \n",
       "53040      way sleep good i not sleep night med n't help  0.1635  \n",
       "53041  public speak tip hi i give presentation work n... -0.6249  \n",
       "53042  i really bad door anxiety not scar i n't lock ... -0.9195  \n",
       "\n",
       "[52681 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"score\"] = df[\"cleaned_text\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "df = df[['statement','cleaned_text','score','status']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ff7aa-9d94-47f6-991b-750829f50ab1",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5353534e-ae03-4260-b815-4d7dab2078bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>score</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>oh gosh</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>trouble sleep confuse mind restless heart tune</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "      <td>-0.7351</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>i shift focus something else i still worried</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>i restless restless month boy you mean</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53038</th>\n",
       "      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n",
       "      <td>nobody take me seriously i 24m dealt depressio...</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53039</th>\n",
       "      <td>selfishness  \"I don't feel very good, it's lik...</td>\n",
       "      <td>selfishness i not feel good like i not belong ...</td>\n",
       "      <td>-0.9830</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53040</th>\n",
       "      <td>Is there any way to sleep better? I can't slee...</td>\n",
       "      <td>way sleep good i not sleep night med n't help</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53041</th>\n",
       "      <td>Public speaking tips? Hi, all. I have to give ...</td>\n",
       "      <td>public speak tip hi i give presentation work n...</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53042</th>\n",
       "      <td>I have really bad door anxiety! It's not about...</td>\n",
       "      <td>i really bad door anxiety not scar i n't lock ...</td>\n",
       "      <td>-0.9195</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52681 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement  \\\n",
       "0                                             oh my gosh   \n",
       "1      trouble sleeping, confused mind, restless hear...   \n",
       "2      All wrong, back off dear, forward doubt. Stay ...   \n",
       "3      I've shifted my focus to something else but I'...   \n",
       "4      I'm restless and restless, it's been a month n...   \n",
       "...                                                  ...   \n",
       "53038  Nobody takes me seriously I’ve (24M) dealt wit...   \n",
       "53039  selfishness  \"I don't feel very good, it's lik...   \n",
       "53040  Is there any way to sleep better? I can't slee...   \n",
       "53041  Public speaking tips? Hi, all. I have to give ...   \n",
       "53042  I have really bad door anxiety! It's not about...   \n",
       "\n",
       "                                            cleaned_text   score   status  \n",
       "0                                                oh gosh  0.0000  Anxiety  \n",
       "1         trouble sleep confuse mind restless heart tune -0.6908  Anxiety  \n",
       "2      wrong back dear forward doubt stay restless re... -0.7351  Anxiety  \n",
       "3           i shift focus something else i still worried -0.2960  Anxiety  \n",
       "4                 i restless restless month boy you mean -0.4939  Anxiety  \n",
       "...                                                  ...     ...      ...  \n",
       "53038  nobody take me seriously i 24m dealt depressio...  0.8696  Anxiety  \n",
       "53039  selfishness i not feel good like i not belong ... -0.9830  Anxiety  \n",
       "53040      way sleep good i not sleep night med n't help  0.1635  Anxiety  \n",
       "53041  public speak tip hi i give presentation work n... -0.6249  Anxiety  \n",
       "53042  i really bad door anxiety not scar i n't lock ... -0.9195  Anxiety  \n",
       "\n",
       "[52681 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"score\"] = df[\"cleaned_text\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "df = df[['statement','cleaned_text','score','status']]\n",
    "df\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob()\n",
    "\n",
    "df[\"Polarity\"] = df[\"cleaned_text\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "print(\"Polarity:\", blob.sentiment.polarity)\n",
    "print(\"Subjectivity:\", blob.sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1d905-f20c-4076-8e9f-0e05af0b6600",
   "metadata": {},
   "source": [
    "## Sentence Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bcefc3f-4010-47bb-bacb-e826e992af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment_label(text):\n",
    "    score = TextBlob(text).sentiment.polarity\n",
    "    if score > 0.1:\n",
    "        return \"positive\"\n",
    "    elif score < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df[\"sentiment_label\"] = df[\"statement\"].apply(get_sentiment_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74fef7-078a-4bc3-9e01-ca59f8bb4ba7",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d80b1f-4046-4b42-b32b-ba0baaec21f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf4a0b0-97a0-421a-bcc4-c75ed1b35de0",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
